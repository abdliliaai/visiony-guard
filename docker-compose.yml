version: '3.8'

services:
  # YOLOv8 ML Detection Service
  ml-service:
    build:
      context: ./src/components/ml
      dockerfile: Dockerfile
    container_name: visiony-ml
    ports:
      - "8001:8001"
    environment:
      - VY_YOLO_WEIGHTS=./weights/yolov8n.pt
      - VY_CONFIDENCE_THRESHOLD=0.5
      - VY_IOU_THRESHOLD=0.45
      - PORT=8001
      - ENV=production
    volumes:
      - ./weights:/app/weights
      - ml-cache:/app/cache
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # Streams Processing Worker
  streams-worker:
    build:
      context: ./src/components/streams
      dockerfile: Dockerfile
    container_name: visiony-streams
    ports:
      - "8002:8002"
      - "8003:8003"  # WebSocket port
    environment:
      - VY_STREAMS_PORT=8002
      - VY_SUPABASE_URL=${VY_SUPABASE_URL}
      - VY_SUPABASE_SERVICE_ROLE=${VY_SUPABASE_SERVICE_ROLE}
      - VY_ML_URL=http://ml-service:8001
      - VY_HLS_SEGMENT_SECONDS=2
      - VY_EVENT_PREPOST_SECONDS=5
      - VY_DETECTION_INTERVAL_MS=5000
      - VY_OUTPUT_DIR=/app/output
      - VY_TEMP_DIR=/app/temp
      - DEBUG=${DEBUG:-false}
    volumes:
      - ./output:/app/output
      - ./temp:/app/temp
    depends_on:
      ml-service:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Redis for caching and session management (optional)
  redis:
    image: redis:7-alpine
    container_name: visiony-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # NGINX for HLS streaming and load balancing (optional)
  nginx:
    image: nginx:alpine
    container_name: visiony-nginx
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./output:/var/www/html/hls:ro
    depends_on:
      - streams-worker
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  ml-cache:
    driver: local
  redis-data:
    driver: local

networks:
  default:
    name: visiony-network
    driver: bridge